{
    "videos": [
        {
            "title": "Intro to Agent Builder",
            "videoId": "44eFf-tRiSg",
            "channel": "OpenAI",
            "publishedAt": "2025-10-06T18:00:06Z",
            "thumbnail": "https://i.ytimg.com/vi/44eFf-tRiSg/hqdefault.jpg",
            "transcript": "Hey everyone, this is Christina from OpenAI. Welcome to Agent Builder 101. Agent Builder is a new visual tool for building AI workflows. You connect nodes and create agents without writing any code. So you can start from templates or build your own from scratch. And it also comes with built-in eval so you can test and understand how your agents perform. When you're ready, you can export the workflow as code or drop it straight into your product. Basically, it's your all-in-one space to design, test, and launch AI agents visually and fast. So, today we're going to show you how to build your first agentic workflow, a helpful travel agent that will help you either build an itinerary or look up flight information. So, we're starting here in the OpenAI platform. Every workflow starts with a start node where you can set input variables or state variables. And today for the travel agent, the defaults are great. Next, I'll connect a classifier agent. I'm going to be building a specialized itinerary agent in addition to a specialized flight agent. And so, I want to first determine which agent I should route to. So, I'll call this classifier. So, you are a helpful travel assistant for classifying whether a message is about an itinerary or a flight. And here I'll specify the output format as JSON. And I'll add a property called classification which will have two options either flight info or itinerary. Great. Next, I'll add in an if else node um to branch based off of the classification. So if put pars.classification classification is flight info then we want to branch to the flight agent and otherwise we want to branch into the um the itinerary agent. So from the flight agent we'll create a new node and we'll call this flight agent. You are a travel assistant. always recommend a specific flight to go to. Use airport codes. And here I'll also give it access to web search so I can have the most up-to-date information about flights. Great. For the itinerary agent, I'll build um an itinerary agent with a new agent node. You are a travel assistant. So build a concise itinerary. Great. I think that's everything we need to get started with our travel agent. So here in run preview, I'll ask it what should I do in a day in Tokyo. And I can see the message going through the workflow that we just created. going through the classifier agent, deciding which category it should go to, seeing that I asked about an itinerary, and then passing it on to the itinerary agent, whereas come up with a concise one-day itinerary for Tokyo. Looks like a great day. Now, for the flight agent, I actually want a richer experience for showing flight information instead of just plain text. And so, I can do that by going and building a widget in our widget studio. Here I've actually already designed um a widget for showing flight information to go from one location to the next with um all the details about the flight. So I can just click download um to download this entire template and then bring that directly to the agent um that we just created here. I'll add it in as the widgets output format. I'll upload this flight widget that we just pulled. Preview it. Everything looks great. And I actually want this to be a bit more customized. Um, and so I will tell it to choose a background color creatively based on the destination. And I'll also ask it to include time zones A.M. or PM. Great. Let's test it out. SFO to Tokyo on October 7th. So here again, we see it moving through the classifier agent um determining whether I'm asking about um a flight or an itinerary, deciding that I'm asking about a flight agent um or deciding that I'm asking about a flight, searching the web, finding a flight for me, and then showing it to me in this rich interactive way. In this case, it's decided that yellow is the color of Tokyo. Um, and so showed that as the background color. Great. So I've now built an agent that I'm happy with and I can publish it directly. Let's call it travel agent here. And I now have a fully deployed agent that is ready to go. Um, I can either use the agents SDK. And here you can see that this is quite a bit of code um for me to manage myself or I can simply take this workflow ID and put it in my product directly using jacket. So that's all. Hope that was helpful and please leave any feedback in the comments and don't forget to subscribe to OpenAI devs for more product updates. Thank you."
        },
        {
            "title": "The AI Agent Gold Rush: Build ChatGPT Apps With Agent Builder (Dev Day Full Breakdown)",
            "videoId": "Qy5gvSoF2qs",
            "channel": "Vaibhav Sisinty",
            "publishedAt": "2025-10-08T13:15:05Z",
            "thumbnail": "https://i.ytimg.com/vi/Qy5gvSoF2qs/hqdefault.jpg",
            "transcript": "While you were sleeping, OpenAI just launched a new app store inside Chat GPT. And guess what? It has 800 million active users on day one. At dev day, Sam Alman revealed agent builder, a tool that could replace tools like N8N or Zapier. Codeex, which makes coding 10 times faster. And with apps like Spotify and Figma built right into ChatGpt, it's now a full app platform. In this video, I'm breaking down all the big announcements you might have missed. Plus, I'll show you how to use OpenAI's new agent builder to build your own AI agent from scratch. No coding needed. Watch till the end or you'll miss out on what could be our generation's biggest opportunity. Let's dive in. Okay, so here's where it gets wild. Forget everything you know about app stores. Apps now just live inside Chat GPT. Now look, OpenAI tried this before with the GPT store. Remember that this is completely different. Apps aren't in some separate store anymore. They're right there in your conversation. Let me show you what I mean. You're in chat GPT, right? You type Spotify, make me a playlist for my party. Boom. Spotify just appears right there. Interactive, personalized, instant, no switching apps, no copying links, nothing. Or you're like, Corsera, teach me about machine learning. And suddenly you've got courses, videos playing right there in the chat while you keep talking to chat GPT. The apps SDK is built on this thing called MCP, model context protocol. Basically means you get full control. Your back end, your data, your UI design, all of it. But here's the actually crazy part. They have this feature called talking to apps. Chat GPT can literally see what you're looking at. You don't have to explain context. So you're watching a Corsera video and something doesn't make sense. Just ask Chat GPT right then and there. It sees the timestamp, knows exactly what's being discussed, explains it to you. The launch partners that are already live include Figma. You can literally sketch something and have it turn into a working diagram. Using Canva, you can start creating posters, slide decks just from conversation. Okay, this one's actually wild. You're chatting and say, \"Show me threebedroom homes in Pittsburgh under 500,000 with a yard.\" Boom. Map appears. Full Zillow experience inside chat GPD. You see a house you like, click it, goes full screen with all the details. Then here's where it gets insane. You can ask chat GPT, \"How close is this house to a dog park?\" And it pulls that context from the Zillow map you're looking at and searches for you. Here's the business side. Monetization is coming. They announced this agentic commerce protocol, which is just fancy talk for instant checkout inside ChatGpt. You can sell directly to 800 million people. If you're a developer, you need to get what just happened here. This is legitimately 2008. Again, back then, the App Store gave you maybe 500 million iPhone users over time. The app's SDK gives you 800 million Chat GPT users. Right now, today, now it's in preview, so not everyone can build yet. But later this year, when the directory launches, that's when it's open season. And for everyone watching who's not a developer, this means your Chat GPT experience is about to get 100 times more useful. Everything you used to have to switch apps for, shopping, learning, planning trips, finding homes, it's all going to be right there in one conversation. The gold rush literally just started. All right, next thing. Agent kit. So, until now, if you wanted to build an AI agent, it was a nightmare. OpenAI just said, \"Forget all that and build everything in one place.\" It's called agent kit. Think of it like a complete toolbox for building AI agents. Everything you need is right there. Here's what's inside. Agent Builder. This is the visual part. You literally just drag boxes around and connect them like you're drawing a flowchart. No coding needed. If you've used those workflow tools before, same idea, but this one's made specifically for AI. Chatkit. This is your chat window. You know how every AI agent needs that chat interface where people type stuff? This is that. Just drop it into your app. Make it look however you want. Your colors, your style. Done. Evils. Okay. So, this is the testing part. And this is huge because with regular automation tools, you can't really test if your AI is doing a good job. This lets you see exactly where your agent messes up, then fix it automatically. That stuff just doesn't exist in normal workflow tools. Connector registry, fancy name for connect your data securely, link it to your company's stuff, third party apps, whatever. It handles all the security headaches for you. So basically, OpenAI looked at tools like Zapier and said, \"What if we made this specifically for AI with all the AI specific stuff already built in?\" Now, here's the part that blew my mind. This engineer at OpenAI, Christina, built a complete working agent on stage in front of everyone, 8 minutes total. She made an agent that figures out what kind of question you're asking, an agent that searches through files to find answers, an agent that plans out schedules, nicel looking result cards, security stuff to protect private information. 8 minutes. That's faster than most people make breakfast. And real companies are already using this stuff. HubSpot, they're using Agent Kit for their customer service AI. This is basically what website builders did for making websites. You used to need to know code. Now you just drag and drop. Agent Kit is doing that for AI agents. All right. So, you want to see how this agent builder thing actually works? Let me walk you through it. First step, getting to agent builder. Super simple. Just open Chrome, type agent builder open AI and you'll see the announcement page introducing agent kit. That's the one. Scroll down a bit and you'll see agent builder with this nice interface preview. Click on that. Now it shows you all the documentation how to use the platform, all that stuff. But let's just jump straight into the platform itself. And boom, this is what you get. Clean interface says create a workflow. Basically build a chat agent with custom logic and tools. Let's create one from scratch. I'll hit create. Okay, so this is the interface. Let me break down what you're looking at. On the left, you've got all your building blocks. Agent nodes, your actual AI agents, MCP, model, context, protocol, connections, guardrails, security stuff, PII protection, file search, that's basically R A, searching through documents, if else, conditional logic, branching paths, while loops for repetitive tasks, user approval, this one's cool, makes the agent ask you before doing anything. So if you want human in the loop, you just drop this in and the agent will pause and ask, \"Hey, should I do this before executing?\" Pretty straightforward, right? All right. So what are we building? I wanted to make something fun. How about an agent that suggests music based on your mood? Like if you're having a rough day, it suggests chill music. If you're pumped up, it gives you energetic stuff. If you're stressed, maybe some meditation tracks. Let's do it. See this default agent node? I'm going to rename it. Let's call it classifier agent. Now the instructions. This is what tells the agent what to do. You are a helpful assistant. Your goal is to understand the user's mood and based on that classify if they are happy, sad, or stressed and suggest a nice playlist for them. Simple enough. Now, here's where it gets specific. I'm going to set the output format to JSON so the next step knows exactly what mood we detected. Click add schema, then add properties. Property one, happy. When the user is happy, this is valid. Property two, sad. When the user is sad, this is valid. Property three, stressed. When the user is stressed, this is valid. Hit update and save. Now, our classifier agent knows exactly how to structure its response. Next up, we need branching logic. Drag over the if/ else node and connect it to the classifier agent. Now, we set up the conditions. If the mood is happy, go this path. Else if the mood is sad, go this path. Else if the mood is stressed, go this path. Perfect. Now we've got three different paths depending on what mood the user is in. All right. Now the fun part. We're going to create three different DJ agents. First one, happy DJ agent. Name happy DJ. Instructions. You are a mood DJ. Your job is to suggest a nice playlist on Spotify when the user's mood is happy. Make sure you choose the best and most liked playlist. Now this needs to actually search Spotify, right? So we add a tool web search. Click that and configure it. Search only in spotify.com. Users location India Bengaluru. Hit add. Same process for the sad DJ agent. Name it sad DJ. Instructions are basically the same. Just change happy to sad. Add web search again. Spotify.com. Same location settings. Last one. Stress DJ agent. Yeah, the names are kind of funny but whatever they work. Same instructions just for stressed mood. Add web search spotify.com same location. Done. Now we need to close this workflow. Grab the end node and connect all three DJ agents to it. Beautiful. We've got start classifier agent if else logic. Three DJ agents and end. That's a complete workflow. Let's publish this thing. I'll name it mood DJ. If you want, you can add chatkit here to embed this in your own website with your domain. Pretty cool. Hit publish. All right. Moment of truth. Let's test it. Click preview to open the chat interface. I'll type, \"Hey, I'm having a productive day at work.\" To make it more productive, suggest me a nice playlist that can keep me going. Watch what happens. The classifier agent reads this, figures out I'm in a good mood, classifies it as happy. The if else node sees happy and roots it to the Happy DJ agent. Happy DJ uses web search on Spotify, finds playlists, and boom, it suggests Loi Beats by Spotify, a super popular instrumental playlist for productive work, even gives me the link, click it, opens right up in Spotify. Perfect. So, that's it. That's how you build an actual working agent in Agent Builder. We went from zero to a fully functional mood-based music recommendation agent in what, like 10 minutes. And this is just a simple example. You can build way more complex stuff with file search guardrails, multiple agents working together. Pretty wild, right? All right. So, we've got our Mood DJ working, but let's make it even better. Right now, it just gives us text responses with links, but what if we could make it more interactive, like have actual buttons you can click? That's where widgets come in. Let me show you how to add that. So, I'm going to click on the Happy DJ agent here. Opens up the side panel. See where it says output format and it's set to text. Let's change that to widget. Boom. Now it asks me to add a widget. I can either upload one or create a new one in widget studio. Let's create one. I'll click create. Okay, this opens up the widget builder in Chatkit Studio. Pretty cool interface. Now I just need to tell it what kind of widget I want. So I'll type build a widget that helps me with the list of Spotify playlists that I should hear. Hit enter and watch this. It's generating the widget right in front of me. And look at this. It's created this nice interactive list with playlist names like deep focus, lowfi workday, morning run, Sunday chill. Each one has its own card. Looks clean, super clickable. Perfect. This is exactly what we need. Now, I'm going to download this. Hit the download button. It saves as a JSON file. Spotify playlist.widget. All right, back to the workflow. Now, I need to actually add this widget to the Happy DJ agent. Click on it again. Go to output format widget. And this time I'll click upload. Let me grab that file. Here it is. Upload it. And nice. It's now listed as Spotify playlist in the widget options. Select that. And we're good. But wait, I have three DJ agents, right? Happy, sad, and stressed. They all need this widget. So, let me do the same thing for sad DJ. Click on it. Change output format to widget. Upload. Select the same file. Apply it. Done. Now, stressed DJ. Same process. Widget. Upload. Apply. Now, let's test this thing and see how it looks. I'll click preview to open the chat. This time, let me try a different prompt. I'll type, \"Hey, I'm working out and need some great music to pump me up and also refresh me.\" Send it. Watch what happens. The classifier agent kicks in, reads my message, figures out I'm pumped up. So, it classifies my mood as happy, roots it to Happy DJ. Happy DJ searches Spotify. And look at this output. It says pumped and refreshed coming right up. And then shows me this beautiful widget with multiple playlists, beast mode, chill hits, each one with its own open button. This is so much better than just text links. So now our Mood DJ doesn't just suggest playlists. It gives you an interactive, clickable interface. One click and you're listening. Way more userfriendly, way more professional. And the best part, we built this entire thing. classifier logic, three specialized agents, custom widgets in like what 15 minutes, no coding. Just drag, drop, configure, and publish. This is the power of agent builder. You can take this concept and build way more complex stuff. Add guardrails, file search, multiple approval steps, whatever you need. The possibilities are pretty wild. All right, that's it. That's how you build a complete agent workflow with custom widgets. Pretty cool, right? Okay, Codeex, let's talk about this. Earlier this year, OpenAI launched Codeex in preview mode. It's their AI software engineering agent that actually writes code for you. Today, Codeex is officially generally available, meaning everyone can use it. Now, it runs on GPT5 Codeex, which is GPT5 specifically trained for coding work. What makes GPT5 Codeex different? It adjusts thinking time based on how complex the task is. Trained on actual real world engineering work, can work independently for over 7 hours straight. optimized for refactoring and code reviews. The numbers on this are genuinely crazy. Sam Alman mentioned at a launch event that within OpenAI itself, almost every engineer now uses Codeex. It was only half of them back in July. They're merging 70% more pull requests every week. Codex automatically reviews basically every PR. It's catching hundreds of bugs every single day before humans even see the code. Daily usage has grown 10 times since early August. Don't just take OpenAI's word for it. Here's who's actually using this in production Cisco. Their code review times are cut in half, 50% faster. Engineers spend way less time on manual checks, more time on actual transformative work. Instacart, they integrated the Codex SDK into their platform. Engineers can spin up environments and complete full tasks with literally one click. Codex even cleans up technical debt automatically. In the live demo at Devday, this guy Roma built a camera control interface from just a sketch live on stage. Codex suggested the VISCA protocol, read the old documentation, wired up an Xbox controller as a joystick, then added voice control using the real-time API. The ending was nuts. He used the Codeex SDK inside the voice agent to reprogram the app in real time. Created movie credits rolling on the fly. Zero code written by hand, just talking and codeex executing. Software engineering just fundamentally changed. Quick model update GPT5 Pro is in the API now. This is the smartest model OpenAI's ever shipped. Available right now to everyone. Perfect for stuff where you need absolute precision. Legal work, financial modeling, healthcare, complex reasoning chains. Next, voice AI just became default infrastructure. Open AI launched GPT Realtime Mini. Smaller, cheaper version of their advanced voice model. Same voice quality, 70% cheaper, natural speech to speech. No weird robotic delays, just real conversations. This is basically the end of voice AI being special. Pretty soon, not having voice in your app is going to feel like not having a search bar. Customer support, productivity tools, cars, education, healthcare, voice everywhere. And at 70% less cost, every single developer can now afford to experiment with it. Last big announcement, Sora 2 in the API. OpenAI actually dropped Sora 2 a week before dev day, but they went hard showcasing it at the event. And they're calling this the GPT 3.5 moment for video, meaning it's the first time AI video is actually good enough for real work, not just demos. Mattel, the toy company, they used Sora 2 API to turn sketches into video concepts in minutes. Designer uploads a sketch of a new toy, adds a description. Sora 2 generates a video showing how the toy moves, how it sounds when kids play with it, how it feels in action. That's how you validate ideas 100 times faster. No prototype building, no video production, no sound design, just sketch to video. It's an API preview. You get full control over video length, aspect ratio, resolution remixing, and variations. You can take a still image and expand it into video or start with one frame and let Sora extend the whole scene. Sam Alman closed dev day with this line. Software used to take months or years to build. You saw today it takes minutes now. You don't need a huge team. You don't need massive infrastructure. You just need a good idea. This is literally 2008 happening again, but way faster and way bigger. The app store created Instagram, Uber, WhatsApp. What's the Chat GPT apps SDK going to create? The developers who start building now won't just ride this wave. They're going to define what this whole platform becomes. So, which one do you think hits first? Distribution, automation, or creation? Drop your take in the comments. I am genuinely curious what you think. If you want daily AI updates like this, join our WhatsApp channel, links in the description. Hit subscribe, ring the bell, all that. And seriously, if you're a developer or you've been thinking about building something, now's the time. Apps SDK is in preview. Agent Kit is live. Codeex is fully available, the platform's open, the distribution's there, the tools are ready. So, what are you going to build?"
        },
        {
            "title": "MASTER ChatGPT Agent Builder Before Its Too Late! Build AI Agents",
            "videoId": "1t2kNEat4-A",
            "channel": "Ishan Sharma",
            "publishedAt": "2025-10-07T13:38:39Z",
            "thumbnail": "https://i.ytimg.com/vi/1t2kNEat4-A/hqdefault.jpg",
            "transcript": "OpenAI just entered the AI agent space and killed at least a dozen startups. Hi everyone, I'm Isan Sharma and OpenAI on Dev Day just unveiled their own agent builder allowing anyone to effortlessly drag and drop and create any agent that they want powered by OpenAI's latest GPT5 models. In this video, I'm going to show you how agent builder works, examples of some agents that you can build with it, and all the different features that you get with agent builder. If you watch till the end, you will also learn how to create and deploy the same agent on the internet for anyone to use. Hit the like button and subscribe and let's get started with the agent builder. All right, so this is what agent builder looks like. You simply have to go to platform.openai.com/agent-builder openai.com/agent-builder and this is the interface that you will see. First of all, we have the create option. But before that, let me actually show you the examples of the types of agent you can build with agent builder. So, first of all, let's have a look at the planning helper agent. What you will see first is the start trigger. This is what triggers and enables the entire agent to start. Then we have a triage agent which basically gathers the key details about any particular business initiative. Then there is a condition. So you can add if and else statements as well which says if it has all the details. So all details equals to true then it will access the launch helper agent which will basically come up with a tailored plan for the user to run this particular business initiative. If the business details are not enough then we will have the get data agent. So collect the missing data from the user look through the conversation to extract the following and then this is basically what the agent entirely looks like. There's also a customer service agent which starts with first classifying the problem that the customer has. So based on let's say return item, cancel subscription, get information, we will have different agents that will be running based on the problem that the person has. For the return item query, we have the return agent which will approve the user and then execute that action. Then we have the retention agent which will try for people to not cancel the subscription. Then we'll have the information agent and what you will notice is that for every agent that we have we are entering instructions. So every agent needs to have an instruction based on which it runs and performs its actions. Then we are also having its model. So in this case it's choosing the GPT 4.1 mini. Then we have tools. So it's currently using get retention offers which is basically a function from the previous module which is the condition over here that we have. All right. Let's try to create a agent from scratch. So we first of all have the start trigger which will basically be a text input. Then we will have this my agent. So I can first of all classify the problem that the person is having. Say I want to build a agent which will help me learn everything about AI. So I first need to classify if I'm looking to get the latest AI news or I want to understand how to use a particular AI tool or I want to learn about the basic fundamentals of AI like machine learning and neural networks. So I can classify this. So I can have a classifier agent which will basically be like you're a helpful classifier agent who will understand the query and categorize it into your AI news AI tool info or AI basics teach. We can keep the model to be GPD5 but the output needs to be a JSON object which would have a schema as so. So we would basically keep it uh property name would be category and you would basically have something like AI news. We could also have AI tool. We could also have AI basics. We could also have AI business idea. Okay, that is pretty much it. Then we can update it and our agent is good to go. We can start one more node over here and this would be a conditional. So we are saying that if the output text and after we find what the query is going to be from the else if statements over here then we can create particular agents for each. For example the AI news agent which would basically be having access to the web. So I'll enable web search I will give it let's add this. I will also write over here AI news agent research the web for the latest updates in the world of generative AI and present it to me in a simple bulleted list of at least 7 to 10 list items and that is it. That is what my AI news agent will look like. Similarly, I can create more agents which would be for AI tool. So this would be AI tool agent. Again this would have access to the web. So I can add this over here. And here I can say give a in-depth description for how to use a particular AI tool along with examples of what you can do with it. For example, if that's what we want to do, then we can have one more AI agent right here which would be for AI basics. So we would basically say explain a AI concept like a teacher with at utmost simplicity. Let's say that's what we want to do with this one. And at the end we can have a AI business idea agent as well. Now again you can also use MCPS over here. That's a great way for you to connect it to different apps and then use them. So if I use this agent for AI business idea, I will again give it access to the internet. So we'll do web search and we will say search the internet to find the most important and interesting business ideas people are deploying with the help of AI. That's it. That's our agent. and else. Else could be just a simple reply. We will basically end it. This would be how we will be ending the loop. And we are good to go. We can now simply just publish our workflow. Could be a AI news helper agent. We can publish it. And it is published. And now and there you go. That's how you create and deploy an agent for anyone to use using agent builder itself. Now there's a lot more that you can do. You can even attach different MCPS to it. So for example, if I create another node over here and I can attach a MCP which would basically allow us to interact with any of the apps like so we have Gmail, we have Google calendar. All of these apps we have access to Zapier, Shopify, we have HubSpot, Stripe, anything that you can use. We can even connect it to Gmail and with Gmail we would now be able to interact with Gmail with the help of this agent itself. So if you want to create a agent which can reply to your emails, you can very easily do that with the help of agent builder itself. But that's just one example of what you can build with the help of agent builder. That was the video. Let me know in the comment section what do you think about the agent builder by OpenAI. What kind of things you can build with it. Let me know below as well. Go try it out. It's available for everyone to try out. You simply need to first of all enter your payment info. And once you do that, you can very well access this agent and start using it from scratch. That was the video. Thanks a lot for watching this till the very end. Let me know if you have any questions in the comment section below. And I'll see you all in the next video. Bye-bye."
        }
    ],
    "video_stats": [
        {
            "title": "Intro to Agent Builder",
            "views": "956187",
            "likes": "30306",
            "comments": "1657",
            "channel": "OpenAI"
        },
        {
            "title": "The AI Agent Gold Rush: Build ChatGPT Apps With Agent Builder (Dev Day Full Breakdown)",
            "views": "10959",
            "likes": "610",
            "comments": "40",
            "channel": "Vaibhav Sisinty"
        },
        {
            "title": "MASTER ChatGPT Agent Builder Before Its Too Late! Build AI Agents",
            "views": "31394",
            "likes": "980",
            "comments": "75",
            "channel": "Ishan Sharma"
        }
    ],
    "reddit_posts": [
        {
            "title": "RIP n8n - OpenAI to launch drag and drop agent builder",
            "subreddit": "n8n",
            "upvotes": 1255,
            "author": "eeko_systems",
            "url": "https://reddit.com/r/n8n/comments/1nz1qcq/rip_n8n_openai_to_launch_drag_and_drop_agent/"
        },
        {
            "title": "OpenAI just dropped \u201cAgentKit, A drag-and-drop AI agent builder. No code, just logic.",
            "subreddit": "ChatGPTPro",
            "upvotes": 324,
            "author": "AskGpts",
            "url": "https://reddit.com/r/ChatGPTPro/comments/1nzqm7z/openai_just_dropped_agentkit_a_draganddrop_ai/"
        },
        {
            "title": "OpenAI employee: right now is the time where the takeoff looks the most rapid to insiders (we don't program anymore we just yell at codex agents) but may look slow to everyone else as the general chatbot medium saturates",
            "subreddit": "OpenAI",
            "upvotes": 179,
            "author": "FinnFarrow",
            "url": "https://reddit.com/r/OpenAI/comments/1nic06w/openai_employee_right_now_is_the_time_where_the/"
        }
    ],
    "x_data": "Here are the latest tweets about \"openai agents\" from nitter.net, formatted in the requested JSON structure:\n\n```json\n{\n  \"tweets\": [\n    {\n      \"username\": \"Dify\",\n      \"handle\": \"@dify_ai\",\n      \"content\": \"OpenAI AgentKit proves visual workflow orchestration still matters. - Dify stays neutral and open across top global models and tools, giving AI engineers the right hammers to craft diverse apps. - Workflows \u00d7 agents > either alone. Dify will keep expanding the potential of Agentic Workflow. - In 2025, easy demos aren\u2019t enough. We\u2019ll continue helping ship stable, production-grade AI systems.\",\n      \"timestamp\": \"2023-10-31T14:00:00Z\",\n      \"retweets\": 1,\n      \"likes\": 6\n    },\n    {\n      \"username\": \"meng shao\",\n      \"handle\": \"@shao__meng\",\n      \"content\": \"OpenAI DevDay 2025 \u4e0a\u53d1\u8868\u7684\u300cContext Engineering and Code Agents with Cursor\u300d\u4e3b\u9898\u6f14\u8bb2\u89c6\u9891\u5df2\u53d1\u5e03\uff0cLee \u56de\u987e\u4e86\u8f6f\u4ef6\u5f00\u53d1\u7684\u5386\u53f2\u6f14\u53d8\uff0c\u8be6\u7ec6\u5206\u4eab\u4e86 Cursor \u5982\u4f55\u901a\u8fc7 AI \u6280\u672f\u63a8\u52a8\u7f16\u7801\u4ece\u7b80\u5355\u9884\u6d4b\u5230\u5168\u81ea\u4e3b\u7f16\u7801\u667a\u80fd\u4f53\u7684\u8f6c\u578b\u3002\",\n      \"timestamp\": \"2023-10-31T13:54:00Z\",\n      \"retweets\": 0,\n      \"likes\": 0\n    },\n    {\n      \"username\": \"Anton P.\",\n      \"handle\": \"@antonp_me\",\n      \"content\": \"The \\\"skills issue\\\" as a reason is just hype. From personal experience: I create instructions for complex AI agents and flows... I don't think I have a problem with prompting \ud83d\ude02... but GPT-5 non-thinking still sucks hard when I'm working with it.\",\n      \"timestamp\": \"2023-10-31T13:49:00Z\",\n      \"retweets\": 0,\n      \"likes\": 2\n    },\n    {\n      \"username\": \"Nishant.viroja\",\n      \"handle\": \"@NishantViroja\",\n      \"content\": \"\ud83d\ude80 OpenAI launched AgentKit: a platform to build, test, and deploy AI agents visually or with code. Create production-ready AI agents in hours, not weeks. \ud83d\udc47 Full breakdown: \ud83d\udd17\",\n      \"timestamp\": \"2023-10-31T13:45:00Z\",\n      \"retweets\": 0,\n      \"likes\": 1\n    },\n    {\n      \"username\": \"Kathirmani Sukumar\",\n      \"handle\": \"@skathirmani\",\n      \"content\": \"My notes based on #OpenAIDevDay opening keynote \ud83e\uddf5 1. Apps inside ChatGPT 2. Building agents using AgentKit 3. Codecs updates 4. API Updates\",\n      \"timestamp\": \"2023-10-31T13:38:00Z\",\n      \"retweets\": 0,\n      \"likes\": 0\n    }\n  ]\n}\n```\n\nFeel free to ask if you need more details or additional information.",
    "ads_data": "I currently don't have direct access to external APIs, such as the \"libraryads\" API you mentioned, to fetch live data. However, I can guide you on how you could do it using code or assist with any other questions you might have about integrating or accessing APIs. Let me know how you'd like to proceed!"
}
{
    "videos": [
        {
            "title": "Intro to Agent Builder",
            "videoId": "44eFf-tRiSg",
            "channel": "OpenAI",
            "publishedAt": "2025-10-06T18:00:06Z",
            "thumbnail": "https://i.ytimg.com/vi/44eFf-tRiSg/hqdefault.jpg",
            "transcript": "Hey everyone, this is Christina from OpenAI. Welcome to Agent Builder 101. Agent Builder is a new visual tool for building AI workflows. You connect nodes and create agents without writing any code. So you can start from templates or build your own from scratch. And it also comes with built-in eval so you can test and understand how your agents perform. When you're ready, you can export the workflow as code or drop it straight into your product. Basically, it's your all-in-one space to design, test, and launch AI agents visually and fast. So, today we're going to show you how to build your first agentic workflow, a helpful travel agent that will help you either build an itinerary or look up flight information. So, we're starting here in the OpenAI platform. Every workflow starts with a start node where you can set input variables or state variables. And today for the travel agent, the defaults are great. Next, I'll connect a classifier agent. I'm going to be building a specialized itinerary agent in addition to a specialized flight agent. And so, I want to first determine which agent I should route to. So, I'll call this classifier. So, you are a helpful travel assistant for classifying whether a message is about an itinerary or a flight. And here I'll specify the output format as JSON. And I'll add a property called classification which will have two options either flight info or itinerary. Great. Next, I'll add in an if else node um to branch based off of the classification. So if put pars.classification classification is flight info then we want to branch to the flight agent and otherwise we want to branch into the um the itinerary agent. So from the flight agent we'll create a new node and we'll call this flight agent. You are a travel assistant. always recommend a specific flight to go to. Use airport codes. And here I'll also give it access to web search so I can have the most up-to-date information about flights. Great. For the itinerary agent, I'll build um an itinerary agent with a new agent node. You are a travel assistant. So build a concise itinerary. Great. I think that's everything we need to get started with our travel agent. So here in run preview, I'll ask it what should I do in a day in Tokyo. And I can see the message going through the workflow that we just created. going through the classifier agent, deciding which category it should go to, seeing that I asked about an itinerary, and then passing it on to the itinerary agent, whereas come up with a concise one-day itinerary for Tokyo. Looks like a great day. Now, for the flight agent, I actually want a richer experience for showing flight information instead of just plain text. And so, I can do that by going and building a widget in our widget studio. Here I've actually already designed um a widget for showing flight information to go from one location to the next with um all the details about the flight. So I can just click download um to download this entire template and then bring that directly to the agent um that we just created here. I'll add it in as the widgets output format. I'll upload this flight widget that we just pulled. Preview it. Everything looks great. And I actually want this to be a bit more customized. Um, and so I will tell it to choose a background color creatively based on the destination. And I'll also ask it to include time zones A.M. or PM. Great. Let's test it out. SFO to Tokyo on October 7th. So here again, we see it moving through the classifier agent um determining whether I'm asking about um a flight or an itinerary, deciding that I'm asking about a flight agent um or deciding that I'm asking about a flight, searching the web, finding a flight for me, and then showing it to me in this rich interactive way. In this case, it's decided that yellow is the color of Tokyo. Um, and so showed that as the background color. Great. So I've now built an agent that I'm happy with and I can publish it directly. Let's call it travel agent here. And I now have a fully deployed agent that is ready to go. Um, I can either use the agents SDK. And here you can see that this is quite a bit of code um for me to manage myself or I can simply take this workflow ID and put it in my product directly using jacket. So that's all. Hope that was helpful and please leave any feedback in the comments and don't forget to subscribe to OpenAI devs for more product updates. Thank you."
        },
        {
            "title": "The AI Agent Gold Rush: Build ChatGPT Apps With Agent Builder (Dev Day Full Breakdown)",
            "videoId": "Qy5gvSoF2qs",
            "channel": "Vaibhav Sisinty",
            "publishedAt": "2025-10-08T13:15:05Z",
            "thumbnail": "https://i.ytimg.com/vi/Qy5gvSoF2qs/hqdefault.jpg",
            "transcript": "While you were sleeping, OpenAI just launched a new app store inside Chat GPT. And guess what? It has 800 million active users on day one. At dev day, Sam Alman revealed agent builder, a tool that could replace tools like N8N or Zapier. Codeex, which makes coding 10 times faster. And with apps like Spotify and Figma built right into ChatGpt, it's now a full app platform. In this video, I'm breaking down all the big announcements you might have missed. Plus, I'll show you how to use OpenAI's new agent builder to build your own AI agent from scratch. No coding needed. Watch till the end or you'll miss out on what could be our generation's biggest opportunity. Let's dive in. Okay, so here's where it gets wild. Forget everything you know about app stores. Apps now just live inside Chat GPT. Now look, OpenAI tried this before with the GPT store. Remember that this is completely different. Apps aren't in some separate store anymore. They're right there in your conversation. Let me show you what I mean. You're in chat GPT, right? You type Spotify, make me a playlist for my party. Boom. Spotify just appears right there. Interactive, personalized, instant, no switching apps, no copying links, nothing. Or you're like, Corsera, teach me about machine learning. And suddenly you've got courses, videos playing right there in the chat while you keep talking to chat GPT. The apps SDK is built on this thing called MCP, model context protocol. Basically means you get full control. Your back end, your data, your UI design, all of it. But here's the actually crazy part. They have this feature called talking to apps. Chat GPT can literally see what you're looking at. You don't have to explain context. So you're watching a Corsera video and something doesn't make sense. Just ask Chat GPT right then and there. It sees the timestamp, knows exactly what's being discussed, explains it to you. The launch partners that are already live include Figma. You can literally sketch something and have it turn into a working diagram. Using Canva, you can start creating posters, slide decks just from conversation. Okay, this one's actually wild. You're chatting and say, \"Show me threebedroom homes in Pittsburgh under 500,000 with a yard.\" Boom. Map appears. Full Zillow experience inside chat GPD. You see a house you like, click it, goes full screen with all the details. Then here's where it gets insane. You can ask chat GPT, \"How close is this house to a dog park?\" And it pulls that context from the Zillow map you're looking at and searches for you. Here's the business side. Monetization is coming. They announced this agentic commerce protocol, which is just fancy talk for instant checkout inside ChatGpt. You can sell directly to 800 million people. If you're a developer, you need to get what just happened here. This is legitimately 2008. Again, back then, the App Store gave you maybe 500 million iPhone users over time. The app's SDK gives you 800 million Chat GPT users. Right now, today, now it's in preview, so not everyone can build yet. But later this year, when the directory launches, that's when it's open season. And for everyone watching who's not a developer, this means your Chat GPT experience is about to get 100 times more useful. Everything you used to have to switch apps for, shopping, learning, planning trips, finding homes, it's all going to be right there in one conversation. The gold rush literally just started. All right, next thing. Agent kit. So, until now, if you wanted to build an AI agent, it was a nightmare. OpenAI just said, \"Forget all that and build everything in one place.\" It's called agent kit. Think of it like a complete toolbox for building AI agents. Everything you need is right there. Here's what's inside. Agent Builder. This is the visual part. You literally just drag boxes around and connect them like you're drawing a flowchart. No coding needed. If you've used those workflow tools before, same idea, but this one's made specifically for AI. Chatkit. This is your chat window. You know how every AI agent needs that chat interface where people type stuff? This is that. Just drop it into your app. Make it look however you want. Your colors, your style. Done. Evils. Okay. So, this is the testing part. And this is huge because with regular automation tools, you can't really test if your AI is doing a good job. This lets you see exactly where your agent messes up, then fix it automatically. That stuff just doesn't exist in normal workflow tools. Connector registry, fancy name for connect your data securely, link it to your company's stuff, third party apps, whatever. It handles all the security headaches for you. So basically, OpenAI looked at tools like Zapier and said, \"What if we made this specifically for AI with all the AI specific stuff already built in?\" Now, here's the part that blew my mind. This engineer at OpenAI, Christina, built a complete working agent on stage in front of everyone, 8 minutes total. She made an agent that figures out what kind of question you're asking, an agent that searches through files to find answers, an agent that plans out schedules, nicel looking result cards, security stuff to protect private information. 8 minutes. That's faster than most people make breakfast. And real companies are already using this stuff. HubSpot, they're using Agent Kit for their customer service AI. This is basically what website builders did for making websites. You used to need to know code. Now you just drag and drop. Agent Kit is doing that for AI agents. All right. So, you want to see how this agent builder thing actually works? Let me walk you through it. First step, getting to agent builder. Super simple. Just open Chrome, type agent builder open AI and you'll see the announcement page introducing agent kit. That's the one. Scroll down a bit and you'll see agent builder with this nice interface preview. Click on that. Now it shows you all the documentation how to use the platform, all that stuff. But let's just jump straight into the platform itself. And boom, this is what you get. Clean interface says create a workflow. Basically build a chat agent with custom logic and tools. Let's create one from scratch. I'll hit create. Okay, so this is the interface. Let me break down what you're looking at. On the left, you've got all your building blocks. Agent nodes, your actual AI agents, MCP, model, context, protocol, connections, guardrails, security stuff, PII protection, file search, that's basically R A, searching through documents, if else, conditional logic, branching paths, while loops for repetitive tasks, user approval, this one's cool, makes the agent ask you before doing anything. So if you want human in the loop, you just drop this in and the agent will pause and ask, \"Hey, should I do this before executing?\" Pretty straightforward, right? All right. So what are we building? I wanted to make something fun. How about an agent that suggests music based on your mood? Like if you're having a rough day, it suggests chill music. If you're pumped up, it gives you energetic stuff. If you're stressed, maybe some meditation tracks. Let's do it. See this default agent node? I'm going to rename it. Let's call it classifier agent. Now the instructions. This is what tells the agent what to do. You are a helpful assistant. Your goal is to understand the user's mood and based on that classify if they are happy, sad, or stressed and suggest a nice playlist for them. Simple enough. Now, here's where it gets specific. I'm going to set the output format to JSON so the next step knows exactly what mood we detected. Click add schema, then add properties. Property one, happy. When the user is happy, this is valid. Property two, sad. When the user is sad, this is valid. Property three, stressed. When the user is stressed, this is valid. Hit update and save. Now, our classifier agent knows exactly how to structure its response. Next up, we need branching logic. Drag over the if/ else node and connect it to the classifier agent. Now, we set up the conditions. If the mood is happy, go this path. Else if the mood is sad, go this path. Else if the mood is stressed, go this path. Perfect. Now we've got three different paths depending on what mood the user is in. All right. Now the fun part. We're going to create three different DJ agents. First one, happy DJ agent. Name happy DJ. Instructions. You are a mood DJ. Your job is to suggest a nice playlist on Spotify when the user's mood is happy. Make sure you choose the best and most liked playlist. Now this needs to actually search Spotify, right? So we add a tool web search. Click that and configure it. Search only in spotify.com. Users location India Bengaluru. Hit add. Same process for the sad DJ agent. Name it sad DJ. Instructions are basically the same. Just change happy to sad. Add web search again. Spotify.com. Same location settings. Last one. Stress DJ agent. Yeah, the names are kind of funny but whatever they work. Same instructions just for stressed mood. Add web search spotify.com same location. Done. Now we need to close this workflow. Grab the end node and connect all three DJ agents to it. Beautiful. We've got start classifier agent if else logic. Three DJ agents and end. That's a complete workflow. Let's publish this thing. I'll name it mood DJ. If you want, you can add chatkit here to embed this in your own website with your domain. Pretty cool. Hit publish. All right. Moment of truth. Let's test it. Click preview to open the chat interface. I'll type, \"Hey, I'm having a productive day at work.\" To make it more productive, suggest me a nice playlist that can keep me going. Watch what happens. The classifier agent reads this, figures out I'm in a good mood, classifies it as happy. The if else node sees happy and roots it to the Happy DJ agent. Happy DJ uses web search on Spotify, finds playlists, and boom, it suggests Loi Beats by Spotify, a super popular instrumental playlist for productive work, even gives me the link, click it, opens right up in Spotify. Perfect. So, that's it. That's how you build an actual working agent in Agent Builder. We went from zero to a fully functional mood-based music recommendation agent in what, like 10 minutes. And this is just a simple example. You can build way more complex stuff with file search guardrails, multiple agents working together. Pretty wild, right? All right. So, we've got our Mood DJ working, but let's make it even better. Right now, it just gives us text responses with links, but what if we could make it more interactive, like have actual buttons you can click? That's where widgets come in. Let me show you how to add that. So, I'm going to click on the Happy DJ agent here. Opens up the side panel. See where it says output format and it's set to text. Let's change that to widget. Boom. Now it asks me to add a widget. I can either upload one or create a new one in widget studio. Let's create one. I'll click create. Okay, this opens up the widget builder in Chatkit Studio. Pretty cool interface. Now I just need to tell it what kind of widget I want. So I'll type build a widget that helps me with the list of Spotify playlists that I should hear. Hit enter and watch this. It's generating the widget right in front of me. And look at this. It's created this nice interactive list with playlist names like deep focus, lowfi workday, morning run, Sunday chill. Each one has its own card. Looks clean, super clickable. Perfect. This is exactly what we need. Now, I'm going to download this. Hit the download button. It saves as a JSON file. Spotify playlist.widget. All right, back to the workflow. Now, I need to actually add this widget to the Happy DJ agent. Click on it again. Go to output format widget. And this time I'll click upload. Let me grab that file. Here it is. Upload it. And nice. It's now listed as Spotify playlist in the widget options. Select that. And we're good. But wait, I have three DJ agents, right? Happy, sad, and stressed. They all need this widget. So, let me do the same thing for sad DJ. Click on it. Change output format to widget. Upload. Select the same file. Apply it. Done. Now, stressed DJ. Same process. Widget. Upload. Apply. Now, let's test this thing and see how it looks. I'll click preview to open the chat. This time, let me try a different prompt. I'll type, \"Hey, I'm working out and need some great music to pump me up and also refresh me.\" Send it. Watch what happens. The classifier agent kicks in, reads my message, figures out I'm pumped up. So, it classifies my mood as happy, roots it to Happy DJ. Happy DJ searches Spotify. And look at this output. It says pumped and refreshed coming right up. And then shows me this beautiful widget with multiple playlists, beast mode, chill hits, each one with its own open button. This is so much better than just text links. So now our Mood DJ doesn't just suggest playlists. It gives you an interactive, clickable interface. One click and you're listening. Way more userfriendly, way more professional. And the best part, we built this entire thing. classifier logic, three specialized agents, custom widgets in like what 15 minutes, no coding. Just drag, drop, configure, and publish. This is the power of agent builder. You can take this concept and build way more complex stuff. Add guardrails, file search, multiple approval steps, whatever you need. The possibilities are pretty wild. All right, that's it. That's how you build a complete agent workflow with custom widgets. Pretty cool, right? Okay, Codeex, let's talk about this. Earlier this year, OpenAI launched Codeex in preview mode. It's their AI software engineering agent that actually writes code for you. Today, Codeex is officially generally available, meaning everyone can use it. Now, it runs on GPT5 Codeex, which is GPT5 specifically trained for coding work. What makes GPT5 Codeex different? It adjusts thinking time based on how complex the task is. Trained on actual real world engineering work, can work independently for over 7 hours straight. optimized for refactoring and code reviews. The numbers on this are genuinely crazy. Sam Alman mentioned at a launch event that within OpenAI itself, almost every engineer now uses Codeex. It was only half of them back in July. They're merging 70% more pull requests every week. Codex automatically reviews basically every PR. It's catching hundreds of bugs every single day before humans even see the code. Daily usage has grown 10 times since early August. Don't just take OpenAI's word for it. Here's who's actually using this in production Cisco. Their code review times are cut in half, 50% faster. Engineers spend way less time on manual checks, more time on actual transformative work. Instacart, they integrated the Codex SDK into their platform. Engineers can spin up environments and complete full tasks with literally one click. Codex even cleans up technical debt automatically. In the live demo at Devday, this guy Roma built a camera control interface from just a sketch live on stage. Codex suggested the VISCA protocol, read the old documentation, wired up an Xbox controller as a joystick, then added voice control using the real-time API. The ending was nuts. He used the Codeex SDK inside the voice agent to reprogram the app in real time. Created movie credits rolling on the fly. Zero code written by hand, just talking and codeex executing. Software engineering just fundamentally changed. Quick model update GPT5 Pro is in the API now. This is the smartest model OpenAI's ever shipped. Available right now to everyone. Perfect for stuff where you need absolute precision. Legal work, financial modeling, healthcare, complex reasoning chains. Next, voice AI just became default infrastructure. Open AI launched GPT Realtime Mini. Smaller, cheaper version of their advanced voice model. Same voice quality, 70% cheaper, natural speech to speech. No weird robotic delays, just real conversations. This is basically the end of voice AI being special. Pretty soon, not having voice in your app is going to feel like not having a search bar. Customer support, productivity tools, cars, education, healthcare, voice everywhere. And at 70% less cost, every single developer can now afford to experiment with it. Last big announcement, Sora 2 in the API. OpenAI actually dropped Sora 2 a week before dev day, but they went hard showcasing it at the event. And they're calling this the GPT 3.5 moment for video, meaning it's the first time AI video is actually good enough for real work, not just demos. Mattel, the toy company, they used Sora 2 API to turn sketches into video concepts in minutes. Designer uploads a sketch of a new toy, adds a description. Sora 2 generates a video showing how the toy moves, how it sounds when kids play with it, how it feels in action. That's how you validate ideas 100 times faster. No prototype building, no video production, no sound design, just sketch to video. It's an API preview. You get full control over video length, aspect ratio, resolution remixing, and variations. You can take a still image and expand it into video or start with one frame and let Sora extend the whole scene. Sam Alman closed dev day with this line. Software used to take months or years to build. You saw today it takes minutes now. You don't need a huge team. You don't need massive infrastructure. You just need a good idea. This is literally 2008 happening again, but way faster and way bigger. The app store created Instagram, Uber, WhatsApp. What's the Chat GPT apps SDK going to create? The developers who start building now won't just ride this wave. They're going to define what this whole platform becomes. So, which one do you think hits first? Distribution, automation, or creation? Drop your take in the comments. I am genuinely curious what you think. If you want daily AI updates like this, join our WhatsApp channel, links in the description. Hit subscribe, ring the bell, all that. And seriously, if you're a developer or you've been thinking about building something, now's the time. Apps SDK is in preview. Agent Kit is live. Codeex is fully available, the platform's open, the distribution's there, the tools are ready. So, what are you going to build?"
        },
        {
            "title": "MASTER ChatGPT Agent Builder Before Its Too Late! Build AI Agents",
            "videoId": "1t2kNEat4-A",
            "channel": "Ishan Sharma",
            "publishedAt": "2025-10-07T13:38:39Z",
            "thumbnail": "https://i.ytimg.com/vi/1t2kNEat4-A/hqdefault.jpg",
            "transcript": "OpenAI just entered the AI agent space and killed at least a dozen startups. Hi everyone, I'm Isan Sharma and OpenAI on Dev Day just unveiled their own agent builder allowing anyone to effortlessly drag and drop and create any agent that they want powered by OpenAI's latest GPT5 models. In this video, I'm going to show you how agent builder works, examples of some agents that you can build with it, and all the different features that you get with agent builder. If you watch till the end, you will also learn how to create and deploy the same agent on the internet for anyone to use. Hit the like button and subscribe and let's get started with the agent builder. All right, so this is what agent builder looks like. You simply have to go to platform.openai.com/agent-builder openai.com/agent-builder and this is the interface that you will see. First of all, we have the create option. But before that, let me actually show you the examples of the types of agent you can build with agent builder. So, first of all, let's have a look at the planning helper agent. What you will see first is the start trigger. This is what triggers and enables the entire agent to start. Then we have a triage agent which basically gathers the key details about any particular business initiative. Then there is a condition. So you can add if and else statements as well which says if it has all the details. So all details equals to true then it will access the launch helper agent which will basically come up with a tailored plan for the user to run this particular business initiative. If the business details are not enough then we will have the get data agent. So collect the missing data from the user look through the conversation to extract the following and then this is basically what the agent entirely looks like. There's also a customer service agent which starts with first classifying the problem that the customer has. So based on let's say return item, cancel subscription, get information, we will have different agents that will be running based on the problem that the person has. For the return item query, we have the return agent which will approve the user and then execute that action. Then we have the retention agent which will try for people to not cancel the subscription. Then we'll have the information agent and what you will notice is that for every agent that we have we are entering instructions. So every agent needs to have an instruction based on which it runs and performs its actions. Then we are also having its model. So in this case it's choosing the GPT 4.1 mini. Then we have tools. So it's currently using get retention offers which is basically a function from the previous module which is the condition over here that we have. All right. Let's try to create a agent from scratch. So we first of all have the start trigger which will basically be a text input. Then we will have this my agent. So I can first of all classify the problem that the person is having. Say I want to build a agent which will help me learn everything about AI. So I first need to classify if I'm looking to get the latest AI news or I want to understand how to use a particular AI tool or I want to learn about the basic fundamentals of AI like machine learning and neural networks. So I can classify this. So I can have a classifier agent which will basically be like you're a helpful classifier agent who will understand the query and categorize it into your AI news AI tool info or AI basics teach. We can keep the model to be GPD5 but the output needs to be a JSON object which would have a schema as so. So we would basically keep it uh property name would be category and you would basically have something like AI news. We could also have AI tool. We could also have AI basics. We could also have AI business idea. Okay, that is pretty much it. Then we can update it and our agent is good to go. We can start one more node over here and this would be a conditional. So we are saying that if the output text and after we find what the query is going to be from the else if statements over here then we can create particular agents for each. For example the AI news agent which would basically be having access to the web. So I'll enable web search I will give it let's add this. I will also write over here AI news agent research the web for the latest updates in the world of generative AI and present it to me in a simple bulleted list of at least 7 to 10 list items and that is it. That is what my AI news agent will look like. Similarly, I can create more agents which would be for AI tool. So this would be AI tool agent. Again this would have access to the web. So I can add this over here. And here I can say give a in-depth description for how to use a particular AI tool along with examples of what you can do with it. For example, if that's what we want to do, then we can have one more AI agent right here which would be for AI basics. So we would basically say explain a AI concept like a teacher with at utmost simplicity. Let's say that's what we want to do with this one. And at the end we can have a AI business idea agent as well. Now again you can also use MCPS over here. That's a great way for you to connect it to different apps and then use them. So if I use this agent for AI business idea, I will again give it access to the internet. So we'll do web search and we will say search the internet to find the most important and interesting business ideas people are deploying with the help of AI. That's it. That's our agent. and else. Else could be just a simple reply. We will basically end it. This would be how we will be ending the loop. And we are good to go. We can now simply just publish our workflow. Could be a AI news helper agent. We can publish it. And it is published. And now and there you go. That's how you create and deploy an agent for anyone to use using agent builder itself. Now there's a lot more that you can do. You can even attach different MCPS to it. So for example, if I create another node over here and I can attach a MCP which would basically allow us to interact with any of the apps like so we have Gmail, we have Google calendar. All of these apps we have access to Zapier, Shopify, we have HubSpot, Stripe, anything that you can use. We can even connect it to Gmail and with Gmail we would now be able to interact with Gmail with the help of this agent itself. So if you want to create a agent which can reply to your emails, you can very easily do that with the help of agent builder itself. But that's just one example of what you can build with the help of agent builder. That was the video. Let me know in the comment section what do you think about the agent builder by OpenAI. What kind of things you can build with it. Let me know below as well. Go try it out. It's available for everyone to try out. You simply need to first of all enter your payment info. And once you do that, you can very well access this agent and start using it from scratch. That was the video. Thanks a lot for watching this till the very end. Let me know if you have any questions in the comment section below. And I'll see you all in the next video. Bye-bye."
        }
    ],
    "video_stats": [
        {
            "title": "Intro to Agent Builder",
            "views": "957204",
            "likes": "30325",
            "comments": "1657",
            "channel": "OpenAI"
        },
        {
            "title": "The AI Agent Gold Rush: Build ChatGPT Apps With Agent Builder (Dev Day Full Breakdown)",
            "views": "11073",
            "likes": "617",
            "comments": "40",
            "channel": "Vaibhav Sisinty"
        },
        {
            "title": "MASTER ChatGPT Agent Builder Before Its Too Late! Build AI Agents",
            "views": "31445",
            "likes": "982",
            "comments": "75",
            "channel": "Ishan Sharma"
        }
    ],
    "reddit_posts": [
        {
            "title": "RIP n8n - OpenAI to launch drag and drop agent builder",
            "subreddit": "n8n",
            "upvotes": 1252,
            "author": "eeko_systems",
            "url": "https://reddit.com/r/n8n/comments/1nz1qcq/rip_n8n_openai_to_launch_drag_and_drop_agent/"
        },
        {
            "title": "OpenAI just dropped \u201cAgentKit, A drag-and-drop AI agent builder. No code, just logic.",
            "subreddit": "ChatGPTPro",
            "upvotes": 326,
            "author": "AskGpts",
            "url": "https://reddit.com/r/ChatGPTPro/comments/1nzqm7z/openai_just_dropped_agentkit_a_draganddrop_ai/"
        },
        {
            "title": "OpenAI employee: right now is the time where the takeoff looks the most rapid to insiders (we don't program anymore we just yell at codex agents) but may look slow to everyone else as the general chatbot medium saturates",
            "subreddit": "OpenAI",
            "upvotes": 177,
            "author": "FinnFarrow",
            "url": "https://reddit.com/r/OpenAI/comments/1nic06w/openai_employee_right_now_is_the_time_where_the/"
        }
    ],
    "x_data": "I encountered errors while trying to scrape tweets from Nitter. The primary issue seems to be with processing the timestamps of the tweets, and a subsequent failure due to an unexpected execution error. \n\nI recommend trying again after some time or checking if there might be changes in the Nitter site's structure that would require adjustments in the code to obtain tweets. Alternatively, if you can access Twitter directly, that might be a more straightforward option for fetching the latest tweets. If there's anything else you'd like me to assist with, feel free to ask!",
    "ads_data": "Here are the top 10 ads running for the query \"openai agents\":\n\n1. **Ad 1**:\n   - **Media Link**: [Instagram](https://l.facebook.com/l.php?u=https%3A%2F%2Fwww.instagram.com%2F_u%2Fthe.product.mentor&h=AT2oW4CDlY8hrGr0gGaaYauyplSd53ZPA6UbHxBu6VpnLZIMykpNCyuiCijwFI5eMnBEAnGCKiUoCNKiPxgjY053r5PN-7SjhIddvpaABrvC45WJpcniT-aIjPRpDXpvDds4jPbqLpfxKKUrx4YhODeEh6U)\n   - **Started Date**: 8 Oct 2025\n   - **Ad Content Visible**: \n     - \ud83d\udea8 Sam Altman just launched AgentKit, ChatGPT\u2019s new Agent Building platform.\n     - #ChatGPT #OpenAI #AgentKit #AIagents #AutomationTools\n   - **Type**: Reel\n     \n2. **Ad 2**:\n   - **Media Link**: [Facebook](https://www.facebook.com/whatchimp/)\n   - **Started Date**: 7 Oct 2025\n   - **Ad Content Visible**: Looking to send personalised bulk messages on WhatsApp without getting banned?\n   - **Type**: Post\n\n3. **Ad 3**:\n   - **Media Link**: [Facebook](https://www.facebook.com/Maaacademybangalore/)\n   - **Started Date**: 7 Oct 2025\n   - **Ad Content Visible**: Learn to build autonomous AI agents that can think, reason, plan, and take action.\n   - **Type**: Post\n\n4. **Ad 4**:\n   - **Media Link**: [Databricks](https://www.facebook.com/databricksinc/)\n   - **Started Date**: 2 Oct 2025\n   - **Ad Content Visible**: Learn how to use Agent Bricks to ship quality AI agents faster.\n   - **Type**: Event Promotion\n\n5. **Ad 5**:\n   - **Media Link**: [Instagram](https://www.facebook.com/100069441114943/)\n   - **Started Date**: 27 Sep 2025\n   - **Ad Content Visible**: \ud83e\udde0 Open Source LLMs \ud83e\udde0 , Edition 16, September Week 4, 2025.\n   - **Type**: Carousel\n\n6. **Ad 6**:\n   - **Media Link**: [Facebook](https://www.facebook.com/61559721694027/)\n   - **Started Date**: 11 Sep 2025\n   - **Ad Content Visible**: \ud83d\ude80 Unlock 100s of Powerful n8n Workflow Templates \u2013 Completely Free!\n   - **Type**: Post\n\n7. **Ad 7**:\n   - **Media Link**: [Outskill](https://www.facebook.com/outskillapp/)\n   - **Started Date**: 8 Aug 2025\n   - **Ad Content Visible**: Join Outskill\u2019s LIVE 2-Day Mastermind and become a Gen AI-Powered Engineer.\n   - **Type**: Workshop Promotion\n\n8. **Ad 8**:\n   - **Media Link**: [Sibidharan Nandhakumar](https://www.facebook.com/sibidharan.me/)\n   - **Started Date**: 7 Jul 2025\n   - **Ad Content Visible**: \ud83d\ude80 AI is rewriting job descriptions. Learn to build AI agents.\n   - **Type**: Video\n\n9. **Ad 9**:\n   - **Media Link**: Not Available\n   - **Started Date**: Not available\n   - **Ad Content Visible**: Not available\n   - **Type**: Not available\n\n10. **Ad 10**:\n    - **Media Link**: Not Available\n    - **Started Date**: Not available\n    - **Ad Content Visible**: Not available\n    - **Type**: Not available\n\nThese ads highlight a variety of AI and automation tools related to OpenAI agents across different platforms and types."
}